{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b57f132",
   "metadata": {},
   "source": [
    "# Элементы кода для получения датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(pathlib.Path.cwd().parent, 'parsing_folder', 'smartlab_sber_downloaded.csv')\n",
    "#path = './project/smartlab_comments_sber.csv'\n",
    "names=['author', 'text_initial', 'text_date', 'url']\n",
    "\n",
    "# # ДЛЯ МФД ЗАПУСКАЕМ:\n",
    "# path = './project/mfd_sber_part2.csv'\n",
    "# names=['author', 'text_initial', 'text_date', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv_and_dropna_smartlab(path, names):\n",
    "    df_smartlab = pd.read_csv(path, names=names)\n",
    "    df_smartlab.dropna(inplace=True)\n",
    "    return df_smartlab\n",
    "\n",
    "df_from_csv = df_from_csv_and_dropna_smartlab(path,names)\n",
    "df_from_csv = df_from_csv[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text_initial</th>\n",
       "      <th>text_date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Advocate</td>\n",
       "      <td>Sergei, о, боги! Боги!)</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5853/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Engineer_M</td>\n",
       "      <td>Advocate, а в профильной целый день сообщают.</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5853/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Sergei</td>\n",
       "      <td>Advocate, да)</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5853/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>any_to_real</td>\n",
       "      <td>Ник, кажется ты разгадал кукла РТСа, бойся</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5854/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>any_to_real</td>\n",
       "      <td>khornickjaadle, предпосылок-то я вижу много и ...</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5854/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>Geist</td>\n",
       "      <td>any_to_real, а эти «скальперы-краткосрочники» ...</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5893/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>Engineer_M</td>\n",
       "      <td>any_to_real,</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5893/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>any_to_real</td>\n",
       "      <td>Engineer_M, прочел сначала «коклов» и подпрыгнул</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5893/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>Engineer_M</td>\n",
       "      <td>any_to_real, так я наглый! Вон, даже когда-то ...</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5893/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Advocate</td>\n",
       "      <td>any_to_real,</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>https://smart-lab.ru/forum/SBER/page5893/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                       text_initial  \\\n",
       "324      Advocate                            Sergei, о, боги! Боги!)   \n",
       "325    Engineer_M      Advocate, а в профильной целый день сообщают.   \n",
       "326        Sergei                                      Advocate, да)   \n",
       "327   any_to_real         Ник, кажется ты разгадал кукла РТСа, бойся   \n",
       "328   any_to_real  khornickjaadle, предпосылок-то я вижу много и ...   \n",
       "...           ...                                                ...   \n",
       "1322        Geist  any_to_real, а эти «скальперы-краткосрочники» ...   \n",
       "1323   Engineer_M                                       any_to_real,   \n",
       "1324  any_to_real   Engineer_M, прочел сначала «коклов» и подпрыгнул   \n",
       "1325   Engineer_M  any_to_real, так я наглый! Вон, даже когда-то ...   \n",
       "1326     Advocate                                       any_to_real,   \n",
       "\n",
       "       text_date                                        url  \n",
       "324   2021-05-27  https://smart-lab.ru/forum/SBER/page5853/  \n",
       "325   2021-05-27  https://smart-lab.ru/forum/SBER/page5853/  \n",
       "326   2021-05-27  https://smart-lab.ru/forum/SBER/page5853/  \n",
       "327   2021-05-28  https://smart-lab.ru/forum/SBER/page5854/  \n",
       "328   2021-05-28  https://smart-lab.ru/forum/SBER/page5854/  \n",
       "...          ...                                        ...  \n",
       "1322  2021-06-17  https://smart-lab.ru/forum/SBER/page5893/  \n",
       "1323  2021-06-17  https://smart-lab.ru/forum/SBER/page5893/  \n",
       "1324  2021-06-17  https://smart-lab.ru/forum/SBER/page5893/  \n",
       "1325  2021-06-17  https://smart-lab.ru/forum/SBER/page5893/  \n",
       "1326  2021-06-17  https://smart-lab.ru/forum/SBER/page5893/  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (Segmenter, NewsEmbedding, NewsMorphTagger, NewsSyntaxParser, Doc, MorphVocab)    \n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "def get_tokenized_text_by_natasha(text_initial):\n",
    "    try:\n",
    "        tokenized_text = []\n",
    "        doc = Doc(text_initial)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        doc.parse_syntax(syntax_parser)\n",
    "        for token1 in doc.tokens:\n",
    "            token1.lemmatize(morph_vocab)\n",
    "            tokenized_text.append(token1.lemma)\n",
    "        tokenized_text = [x for x in tokenized_text if x and x not in '- \\t\\n.,;:!?(—)«»<>„“…+..?…?/©']\n",
    "        return tokenized_text\n",
    "    except:\n",
    "        return text_initial\n",
    "\n",
    "def df_with_tokens_and_date(df_from_csv):\n",
    "    df_temp = df_from_csv.copy()\n",
    "    df_temp['tokenized_text'] = df_temp.text_initial.apply(get_tokenized_text_by_natasha)\n",
    "    from collections import defaultdict\n",
    "    dates = defaultdict(list)\n",
    "    dates2 = defaultdict(str)\n",
    "    for i in range(len(df_temp)):\n",
    "        dates[df_temp.text_date.iloc[i]].extend(df_temp.tokenized_text.iloc[i])\n",
    "        dates2[df_temp.text_date.iloc[i]] = dates2[df_temp.text_date.iloc[i]] + df_temp.text_initial.iloc[i]\n",
    "    df_with_tokens = pd.DataFrame(index=pd.DatetimeIndex(dates.keys()), data=None)\n",
    "    df_with_tokens['text'] = dates.values()\n",
    "    df_with_tokens['text_initial'] = dates2.values()\n",
    "    df_with_tokens.index.name = 'date'\n",
    "    df_with_tokens.sort_index(inplace=True)\n",
    "    return df_with_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_tokens = df_with_tokens_and_date(df_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_tokens_and_price(df_with_tokens):\n",
    "    df_temp = df_with_tokens.copy()\n",
    "    target = pd.read_csv('sbertarget.csv', index_col='Date')\n",
    "    datetime_index = pd.DatetimeIndex(target.index)\n",
    "    target.index = datetime_index\n",
    "    df_temp['price'] = target['Price']\n",
    "    df_temp.price.fillna(0, inplace=True)\n",
    "    for i in range(len(df_temp)-1):\n",
    "        if df_temp.price.iloc[i] == 0 and df_temp.price.iloc[i+1] == 0:\n",
    "            df_temp.text.iloc[i-1].extend(df_temp.text.iloc[i])   #.extend(df2.text.iloc[i+1]))\n",
    "            df_temp.text.iloc[i-1].extend(df_temp.text.iloc[i+1])\n",
    "    df_with_tokens_and_price = df_temp[df_temp.price!=0]\n",
    "    \n",
    "    return df_with_tokens_and_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_tokens_and_price = get_df_with_tokens_and_price(df_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df_with_tokens_and_price):\n",
    "    df_temp = df_with_tokens_and_price.copy()\n",
    "    target_real = pd.read_csv('df_price.csv', names=['date', 'price', 'class'])\n",
    "    datetime_series = pd.to_datetime(target_real['date'])\n",
    "    datetime_index = pd.DatetimeIndex(datetime_series.values)\n",
    "    target_real.index = datetime_index\n",
    "    df_temp['target_real'] = target_real['class']\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_smartlab = get_dataset(df_with_tokens_and_price)\n",
    "#df_dataset_mfd = get_dataset(df_with_tokens_and_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dataset_smartlab.to_pickle('df_dataset_smar[pkltlab.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
